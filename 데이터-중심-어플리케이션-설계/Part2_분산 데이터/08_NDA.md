> *이봐 방금 널 만났어  
네트워크가 느려터졌군  
하지만 여기 내 데이터가 있으니  
아마도 저장해주길*  
> 
> 카일 킹스베리, 칼리 레이 젭슨과 네트워크 분단의 위험성(2013)
- 이번 장에서는 현업에서 일어나는 문제점들을 맛보고, 우리가 기댈 수 있는 것과 그렇지 않은 것을 이해하게 된다.
- 결국 엔지니어로서의 우리의 임무는 모든 게 잘못되더라도 제 역할을 해내는 시스템을 구축하는 것이다.
- 분산 시스템의 상태에 대해 생각하는 방법과 무슨 일이 일어났는지 추론하는 방법을 알아보자!

<br>

**[단어 사전]**

| 단어 | 의미 |
| --- | --- |
| 비동기 패킷 네트워크(asynchronous packet network) | 네트워크에서 패킷이 고정된 시간 간격 없이 비동기적으로 전송되는 방식 |
| 네트워크 분단(network partition) or 네트워크 분리(netsplit) | 네트워크 결함으로 인해 네트워크 일부가 다른 쪽과 차단되는 현상 |
| 기약 없는 지연(unbounded delay) | 패킷이 도착하는 데 걸리는 시간에 상한치가 없는 개념 |
| 흐름 제어(flow control) | 노드가 네트워크 링크나 수신 노드에 과부하를 가하지 않도록 자신의 송신율을 제한하는 것 |
| 혼잡 회피(congestion avoidance) | 네트워크가 혼잡해지기 전에 트래픽을 조절하는 기법 |
| 배압(backpressure) | 네트워크 또는 시스템에서 처리 속도를 제어하기 위해 데이터를 일시적으로 지연시키는 기법 |
| 경계 경로 프로토콜(BGP, Border Gateway Protocol) | 인터넷 상의 자율 시스템(AS, Autonomous System) 간 경로를 결정하는 라우팅 프로토콜(글로벌 네트워크에서 최적의 데이터 전송 경로를 찾는 역할) |
| 지터(jitter) | 네트워크 지연(latency)이나 응답 시간(response time)이 일정하지 않고 변동하는 현상 |
| 시계 드리프트(drift) | 컴퓨터의 시계가 더 빠르거나 느리게 실행되는 현상 |
| 윤초(leap seconds) | 지구의 자전 속도와 국제 표준시(UTC) 간의 오차를 보정하기 위해 추가 또는 제거하는 1초 |
| 플래시 크래시(flash crashes) | 주가나 채권 금리가 급락하는 상황 |

<br>

## 새롭게 알게된 점(NEW)

### 결함과 부분 장애

- 단일 컴퓨터에서 실행되는 소프트웨어를 믿지 못할 근본적인 이유는 없다. 하드웨어가 올바르게 동작하면 같은 연산은 항상 같은 결과를 낸다.
- 분산 시스템에서는 더 이상 이상화된 시스템 모델에서 동작하지 않는다.
- `부분 장애(partial failure)` : 시스템의 어떤 부분은 잘 동작하지만 다른 부분은 예측할 수 없는 방식으로 고장나는 것 (비결정적)
- ***비결정성**과 **부분 장애 가능성**이 분산 시스템을 다루기 어렵게 한다.*

<br>

### 신뢰성 없는 네트워크

> 이 책에서 주로 다루는 분산 시스템은 비공유 시스템, 즉 네트워크로 연결된 다수의 장비다.
>
- 특별한 하드웨어가 필요하지 않아서 상대적으로 저렴하다.
- 상품화된 클라우드 서비스를 활용할 수 있다.
- 지리적으로 분산된 여러 데이터센터에 중복 배치함으로써 높은 신뢰성을 확보할 수 있다.

하지만, `비동기 패킷 네트워크(asynchronous packet network)`이므로 메시지의 도착을 보장하지 않는다는 문제점이 있다. `타임아웃`으로 처리할 수 있지만 시간이 지나 메시지가 수신 측에 도착할 수도 있다.

<br>

**[1] 현실의 네트워크 결함**

> 네트워크 결함이 드물더라도 결함이 일어날 수 있다는 사실은 여러분의 소프트웨어가 이를 처리할 수 있어야 한다는 뜻이다. 네트워크 상으로 통신할 때마다 실패할 가능성이 있다. 피할 방법은 없다.
>
- 반드시 네트워크 결함을 견뎌내도록(tolerating) 처리할 필요는 없다.
- 네트워크가 평상시에는 믿을 만하다면 네트워크에 문제가 생겼을 때 사용자에게 오류 메시지를 보여주는 것도 괜찮다.

<br>

**[2] 타임아웃과 기약 없는 지연**

> 타임아웃만이 결함을 감지하는 확실한 수단이라면 타임아웃은 얼마나 길어야 할까? 유감스럽게도 간단한 답은 없다.
>
- 타임아웃이 길면, 노드가 죽었다고 선언될 때까지 기다리는 시간이 길어진다.
- 타임아웃이 짧으면, 결함은 빨리 발견하지만 노드가 일시적으로 느려졌을 뿐인데도 죽었다고 잘못 선언한 위험이 높아진다.
- 비동기 네트워크는 `기약 없는 지연(unbounded delay)`이 있고, 서버 구현은 대부분 어떤 최대 시간 내에 요청을 처리한다고 보장할 수 없다.

<br>

**[3] 네트워크 혼잡과 큐 대기**

> 컴퓨터 네트워크에서 패킷 지연의 변동성은 큐 대기 때문인 경우가 많다.
>


- `네트워크 혼잡(network congestion)` : 네트워크 링크가 붐벼 패킷이 슬롯을 얻을 수 있을 때까지 기다려야 하는 현상
- 네트워크는 잘 동작하고 있더라도 들어오는 데이터가 많아서 스위치 큐를 꽉 채울 정도가 되면 패킷이 유실되어 재전송해야 한다.
- 패킷이 목적지 장비에 도착했다고 하더라도 CPU 코어가 당장 처리하지 못한다면, 운영체제가 큐에 넣어 둔다. 장비의 부하에 따라 큐에서 대기하는 시간이 달라진다.
- 가상 환경에서 실행되는 운영체제는 다른 가상 장비가 CPU 코어를 사용하는 동안 수십 밀리초 동안 멈출 때가 흔하다.

<br>

1️⃣ **TCP**

- `흐름 제어`를 수행하기 때문에, 데이터가 네트워크로 들어가기 전에도 부가적인 큐 대기가 이루어질 수 있다.
- 타임아웃 안에 확인 응답을 받지 않으면 패킷 손실을 예상하고 자동으로 `재전송`한다. 이때 지연이 발생한다.

<br>

2️⃣ 해결 방법

❶ `지연의 변동성`을 알아내기 위해 긴 기간에 여러 장비에 걸쳐 `네트워크 왕복 시간의 분포`를 **측정**한다. 이후에 애플리케이션의 특성을 고려해서 장애 감지 지연과 이른 타임아웃의 위험성 사이에서 적절한 트레이드오프를 결정한다.

❷ 시스템이 지속적으로 응답 시간과 그들의 변동성을 측정하고 관찰된 응답 시간 분포에 따라 타임아웃을 자동으로 조절하게 한다.

- 이때 `파이 증가 장애 감지기(Phi accrual failure detector)`를 사용한다. **아카(Akka)**와 **카산드라**가 이를 사용하며, TCP 재전송 타임아웃도 비슷하게 동작한다.

<br>

**[4] 동기 네트워크 대 비동기 네트워크**

> 패킷 전송 지연 시간의 최대치가 고정돼 있고 패킷을 유실하지 않는 네트워크에 기댈 수 있다면 분산 시스템은 훨씬 더 단순해진다. *왜 하드웨어 수준에서 이 문제를 해결하고 네트워크를 신뢰성 있게 만들어서 소프트웨어에서는 걱정할 필요가 없게 할 수 없을까?*
>
- 전화 네트워크에서 통화를 할 때는 `회선(circuit)`이 만들어진다. 통화를 하는 두 명 사이에 있는 전체 경로를 따라서 그 통화에 대해 고정되고 보장된 양의 대역폭이 할당된다. 회선은 통화가 끝날때까지 유지된다.
- 전화 네트워크의 경우 `동기식`이다. 데이터가 여러 라우터를 거치더라도 큐 대기 문제를 겪지 않는다.
    - 네트워크의 다음 `홉(hop)`에 통화당 16비트의 공간이 이미 할당됐기 때문이다.
    - 큐 대기가 없으므로 `네트워크 종단 지연 시간의 최대치`가 **고정**돼 있다.
    - 이를 `제한 있는 지연(bounded delay)`라고 한다.

<br>

**1️⃣ 왜 데이터센터 네트워크와 인터넷은 패킷 교환을 사용할까?**

- `순간적으로 몰리는 트래픽(bursty traffic)`에 **최적화**됐기 때문이다.
    - 순간적으로 몰리는 데이터 전송에 회선을 쓰면 네트워크 용량을 낭비하고 전송이 불필요하게 느려진다.
- 반대로 `TCP`는 **가용한 네트워크 용량**에 맞춰 **데이터 전송률**을 **동적으로 조절**한다.

<br>

> 🏷️ 지연 시간과 자원 사용률  
일반적으로 지연의 변동이 심한 것은 동적 자원 분할의 결로 생각할 수 있다. 
전화 스위치 사이의 선로는 `정적 방식`으로 분배된다. 선로를 쓰는 회선이 하나 뿐이어도 
선로 전부를 사용할 때처럼 똑같이 고정된 양의 대역폭을 할당한다. 반대로 인터넷은 대역폭을 `동적`으로 공유한다. 
전송 측은 가능하면 빨리 패킷을 선로로 보내기 위해 서로 밀고 밀치며 `네트워크 스위치`가 빈번하게 어떤 패킷을 보낼지(즉 대역폭 할당) 결정한다. 
이 방법은 큐 대기가 생기는 단점이 있지만 선로를 최대한 사용한다는 이점이 있다. 
선로는 고정된 비용이므로 **사용률이 높을수록 이 선로로 보내는 개별 바이트의 비용은 더 싸진다.**
네트워크에서 변동이 큰 지연은 자연 법칙이 아니라 단지 **비용/이득 트레이드오프의 결과**일 뿐이다.


→ *현재 배포된 기술로는 네트워크의 지연과 신뢰성에 대해 어떤 보장도 할 수 없다.* 네트워크 혼잡, 큐, 대기, 기약 없는 지연이 발생할 것이라고 가정해야 한다. 결과적으로 타임아웃에 “올바른” 값은 없으며 실험을 통해 결정해야 한다.

<br>

### 신뢰성 없는 시계

> 애플리케이션은 다음과 같은 질문에 대답하기 위해 다양한 방식으로 시계에 의존한다.
>

| 분류 | 지속 시간 측정                                                                                                                      | 시점 기술                                                                                                             |
| --- |-------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------|
| 예시 | 요청을 보낸 시점과 응답을 받은 시점 사이의 시간 구간                                                                                                | 특정 날짜의 특정 시간에 발생한 이벤트                                                                                             |
| 질문 | 1. 이 요청이 타임아웃됐나?<br>2. 이 서비스의 99분위 응답 시간은 어떻게 되나?<br>3. 이 서비스는 지난 5분 동안 평균 초당 몇 개의 질의를 처리했나?<br>4. 사용자가 우리 사이트에서 시간을 얼마나 보냈나? | 1. 이 기사가 언제 게시됐나?<br>2. 며칠 몇 시에 미리 알림 이메일을 보내야 하나?<br>3. 이 캐시 항목은 언제 만료되나?<br>4. 로그 파일에 남은 이 오류 메시지의 타임스탬프는 무엇인가? |
- 분산 시스템에서는 **통신이 즉각적이지 않으므로 시간을 다루기 까다롭다.**
  - 메시지가 네트워크를 거쳐서 한 장비에서 다른 장비로 전달되는 데 시간이 걸린다. 네트워크 변동성으로 여러 장비가 관련될 때 **어떤 일이 발생한 순서를 알아내기 어렵게** 만들기도 한다.
- 네트워크에 있는 개별 장비는 *자신의 시계*를 갖고 있다. 그것은 실제 하드웨어 장치로 보통 `수정 발진기(quarts crystral oscillator)`다. 이 장치는 완벽히 정확하지는 않아서 각 장비는 자신만의 시간 개념이 있으며 이는 다른 장비보다 약간 빠를 수도 느릴 수도 있다.
- 시간을 어느 정도 `동기화`할 수 있다. 가장 널리 쓰이는 메커니즘은 `네트워크 시간 프로토콜(Network Time Protocol, NTP)`로 서버 그룹에서 보고한 시간에 따라 컴퓨터 시계를 조정할 수 있게 한다. 이 서버들은 다시 GPS 수신자 같은 더욱 정확한 시간 출처로 부터 시간을 얻는다.

<br>

**[1] 단조 시계 대 일 기준 시계**

| 종류 | 일 기준 시계                                                                        | 단조 시계                                                                  |
| --- |--------------------------------------------------------------------------------|------------------------------------------------------------------------|
| 반환값 | 현재 날짜와 시간 (특정 달력 기준)                                                           | 경과 시간 (시스템 가동 이후 흐른 시간)                                                |
| 예시 | - Linux : clock_gettime(CLOCK_REALTIME)<br>- Java : System.currentTimeMillis() | - Linux : clock_gettime(CLOCK_MONOTONIC)<br>- Java : System.nanoTime() |
| 동기화 / 조정 | 보통 NTP로 동기화되며, 로컬 시계가 너무 빠르면 강제로 리셋 수행                                         | NTP에 의해 진도(진행 속도)를 조정할 수 있지만 다른 노드와 비교 불가능                             
|
| 윤초 영향 | 윤초를 종종 무시해 경과 시간 측정에 부적합                                                       | 무관                                                                     |
| 해상도 | 매우 거친(coarse-grained) 해상도를 가지며 오래된 윈도우 시스템에서는 10밀리초 단위 (최근 시스템은 개선됨)           | 해상도가 보통 상당히 좋으며 마이크로초나 그 이하 단위로 측정 가능                                  |
- `에포크` : 그레고리력에 따르면 UTC(협정세계시) 1970년 1월 1일 자정을 가리킨다.
- 분산 시스템에서 **경과 시간을 재는 데 단조 시계를 쓰는 것**은 일반적으로 **괜찮다**. 다른 노드의 시계 사이에 동기화가 돼야 한다는 가정이 없고 측정이 약간 부정확해도 민감하지 않기 때문이다.

**[2] 시계 동기화와 정확도**

- UTC와 100마이크로초 이내로 동기화하는 정확도는 `GPS 수신기`, `정밀 시간 프로토콜(PTC, Precision Time Protocol)`과 세심한 배포 및 모니터링을 사용해서 달성할 수 있다.

**[3] 동기화된 시계에 의존하기**

> 동기화된 시계가 필요한 소프트웨어를 사용한다면 필수적으로 모든 장비 사이의 시계 차이를 조심스럽게 모니터링해야 한다.
>
- 다른 노드와 시계가 너무 차이나는 노드는 죽은 것으로 선언되고 클러스터에서 제거돼야 한다.

<br>

**1️⃣ 이벤트 순서화용 타임스탬프**

> 🤔 두 클라이언트가 분산 데이터에 쓰면 누가 먼저 쓰게 될까? 누가 쓴 게 더 최근 것이 될까?
>
- 시계가 틀렸다면 순서가 뒤바뀐 채 `최종 쓰기 승리(LWW, last write wins)`에 의해 **데이터가 유실**될 수 있다.
- `논리적 시계(logical clock)`을 사용해 진동하는 수정(quarts crystal) 대신 증가하는 `카운터`를 기반으로 이벤트의 상대적이 순서만 측정해 순서화를 하자!

<br>

**2️⃣ 전역 스냅숏용 동기화된 시계**

> 분산 데이터베이스에서 스냅숏 격리를 사용하려면, 전역 단조 증가 트랜잭션 ID를 생성해야 한다. 작고 빠른 트랜잭션이 많으면 분산 시스템에서 트랜잭션 ID 생성은 방어할 수 없는 병목이 된다.
>
- `스패너`는 `트루타임(TrueTime) API`가 보고한 시계 신뢰 구간을 사용해 신뢰 구간이 겹치지 않게 트랜잭션을 커밋하여 스냅숏 격리를 구현한다.

<br>

### 프로세스 중단

> 파티션마다 리더가 하나씩 있는 데이터베이스가 있다고 가정한다. 리더만 쓰기를 받아들이도록 허용된다. 노드가 여전히 리더인지, 안전하게 쓰기를 받아들일 수 있을지 어떻게 알 수 있을까?
>

```java
/**
* 리더가 임차권을 얻어 만료될 때까지 리더일 것이라고 알게 하고, 
* 임차권이 만료되기 전에 주기적으로 갱신되며 
* 장애 발생 시 갱신이 불가하게 한다.
*/
while (true) {
	request = getIncomingRequest(); // 요청
	
	// 항상 임차권이 적어도 10초는 남아 있게 보장한다
	if (lease.expiryTimeMillis - System.currentTimeMillis() < 10000) {
		lease = lease.renew(); // 갱신
	}
	
	// 임차권이 유효할 때
	if (lease.isValid()) { 
		process(request);	// 요청 처리 
	}
}
```

**1️⃣ 코드의 문제점**

- 동기화된 시계에 의존해 시간 계산이 달라질 수 있다.
- 로컬 단조 시계만 사용하더라도, 시간을 확인하는 시점과 요청이 처리되는 시점 사이에 지연 시간이 생기면 이미 임차권은 만료된다.

**2️⃣ 해결 방법**

- 실행 중인 스레드를 어떤 시점에 `선점(preempt)`하고 얼마간의 시간이 흐른 후 재개한다.
- 단일 장비에서는 스레드 안전하게 만들기 위해 `뮤텍스`, `세마포어` 등을 구현할 수 있지만 분산 시스템은 공유 메모리가 없고 신뢰성 없는 네트워크를 통해 메시지를 보낼 수만 있기 때문에 분산 시스템용으로 바로 변형할 수 없다.

<br>

> **🏷️ NOTE**
분산 시스템의 노드는 어느 시점에 실행이 상당한 시간 동안 멈출 수 있다고 가정해야 한다.

<br>

**[1] 응답 시간 보장**

> 🤔 자동차의 차내 센서가 지금 충돌이 날 것을 감지했는데, 에어백 방출 시스템의 GC 중단 때문에 에어백이 늦게 방출되지 않게 하려면 어떻게 해야 할까?
>
- 프로세스가 명시된 간격의 CPU 시간을 할당받을 수 있게 보장되도록 스케줄링해 주는 `실시간 운영체제(RTOS, real-time operating system)`가 필요하다.
- 라이브러리 함수는 최악의 실행 시간을 문서화해야 한다.
- 동적 메모리 할당은 제한되거나 완전히 금지될 수도 있다. (GC가 너무 많은 일을 하지 않도록 보장해야 한다.)

<br>

> 🏷️ **가비지 컬렉션의 영향 제한하기**  
GC 중단이 필요한 노드가 있을 때, 그 노드에 새로운 요청을 보내지 않고 GC를 실행할 동안 다른 노드에서 요청을 처리하고 기다린다. 지연 시간에 민감한 금융 거래 시스템 중 몇몇은 GC 중단에 대처하기 위해 이 방법을 택한다. 혹은 수명이 짧은 객체만 GC를 사용하고 수명이 긴 객체의 전체 GC가 필요하기 전에 주기적으로 프로세스를 재시작하는 방법도 있다.

<br>

### 지식, 진실, 그리고 거짓말

> 분산 시스템에는 공유 메모리가 없고 지연 변동이 큰 신뢰할 수 없는 네트워크를 통해 메시지를 보낼 수 있을 뿐이며 부분 장애, 신뢰성 없는 시계, 프로세스 중단에 시달릴 수 있다.
>
- 우리는 동작(시스템 모델)에 관해 정한 가정을 명시하고, 이런 가정을 만족시키는 방식으로 실제 시스템을 설계할 수 있다.

<br>

**[1] 진실은 다수결로 결정된다**

> 🤔 네트워크 결함으로 하나의 노드에서 응답이 유실되어 다른 노드들은 해당 노드가 죽었다고 선언하지만 해당 노드는 그 사실조차 알지 못한다면, 한 노드에만 의존하는 것이 괜찮을까?
>

여러 분산 알고리즘은 `정족수(quorum)`에 의존한다. 특정한 노드 하나에 대한 의존을 줄이기 위해 결정을 하려면 여러 노드로부터 어떤 최소 개수의 투표를 받아야 한다.

<Br>

**1️⃣ 리더의 잠금**

> 🤔 어떤 파일에 한 번에 클라이언트 하나씩만 접근하도록 보장하고 싶을 때, 프로세스 중단이 일어나면 어떻게 될까?
>

분산시스템에서는 이를 구현할 때 위와 같은 상황이 발생할 수 있으므로 주의해야 한다.

<Br>

**2️⃣ 펜싱 토큰**


- 잠금 서버가 잠금이나 임차권을 승인할 때마다 `펜싱 토큰(fencing token)`도 반환하게 하면 [2]의 상황을 해결할 수 있다.
- 잠금 서비스로 `주키퍼`를 사용하면 `트랜잭션 ID(zxid)`나 `노드 버전(cversion)`을 펜싱 토큰으로 사용할 수 있다.

<br>

**[2] 비잔틴 결함**

> 🤔 노드가 고의로 시스템의 보장을 무너뜨리려한다면 가짜 펜싱 토큰을 포함한 메시지를 보낼 수도 있지 않을까?
>
- `비잔틴 결함(Byzantine fault)` : 노드가 임의의 결함이 있거나 오염된 응답을 보내는 위험 동작
- `비잔틴 장군 문제(Byzantine Generals Problem)` :  비잔틴 결함으로 신뢰할 수 없는 환경에서 합의에 도달하는 문제
- 대부분의 비잔틴 내결함성 알고리즘은 노드의 2/3 이상의 압도적 다수가 올바르게 동작하기를 요구한다.
- 노드들이 일반적으로 정직하다고 가정하지만 오염된 패킷이나, 사용자 입력같은 것들을 보호하기 위한 메커니즘을 소프트웨어에 추가하는 게 가치가 있을 수 있다. (체크섬 사용, 정상성 점검 등)

<br>

**[3] 시스템 모델과 현실**

> 분산 시스템 문제를 해결하기 위해 많은 알고리즘이 설계되고 있다. 시스템에서 발생할 것으로 예상되는 결함의 종류를 정형화한 `시스템 모델`을 알아보자.
>

<br>

**1️⃣ 시스템 모델의 종류**

**❶ 타이밍 가정 시스템 모델**

| 동기식 모델 | 부분 동기식 모델 | 비동기식 모델 |
| --- | --- | --- |
| 네트워크 지연, 프로세스 중단, 시계 오차에 모두 제한이 있다고 가정한다. | 시스템이 대부분의 시간에는 동기식 시스템처럼 동작하지만 때대로 네트워크 지연, 프로세스 중단, 시계 드리프트의 한계치를 초과한다는 뜻이다. (현실적인 모델) | 타이밍에 대한 어떤 가정도 할 수 없다. 어떤 알고리즘은 비동기식 모델용으로 설계할 수 있지만 매우 제한적이다. |

<br>

❷ **노드 장애 - 노드용 시스템 모델**

| 죽으면 중단하는(crash-stop) 결함 | 죽으면 복구하는(crash-recovery) 결함 | 비잔틴(임의적인) 결함 |
| --- | --- | --- |
| 노드에 장애가 나는 방식은 죽는 것뿐이라고 가정한다. | 노드가 어느 순간에 죽을 수 있지만 어느 시간이 흐른 후 다시 응답하기 시작할 것이라고 가정한다. | 노드는 다른 노드를 속이거나 기만하는 것을 포함해 전적으로 무슨 일이든 할 수 있다. |

<br>

> 🔉 현실 시스템을 모델링하는 데는 `죽으면 복구하는 결함`을 지닌 `부분 동기식 모델`이 일반적으로 가장 유용한 모델이다.


<br>

**2️⃣ 알고리즘의 정확성**

> 🤔 분산 알고리즘은 위의 모델에 어떻게 대응할 수 있을까?
>

알고리즘은 시스템 모델에서 발생하리라고 가정한 모든 상황에서 그 속성들을 항상 만족시키면 해당 시스템 모델에서 정확하다. 펜싱 토큰이라면, 그 알고리즘은 다음 속성을 지닌다.

- **안정성 속성**
  - `유일성` : 펜싱 토큰 요청이 같은 값을 반환하지 않는다.
  - `단조 일련번호` : 요청 x가 토큰 t1을, 요청 y가 t2를 반환했고 2가 시작되기 전에 x가 완료됐다면 t1 < t2를 만족한다.
- **활동성 속성**
  - `가용성` : 펜싱 토큰을 요청하고 죽지 않은 노드는 결국에는 응답을 받는다.

<br>

3️⃣ **안정성과 활동성**

- 분산 알고리즘은 시스템 모델의 모든 상황에서 `안정성(safety) 속성`이 항상 만족되기를 요구하는 게 일반적이다.
- `활동성(liveness) 속성`에 대해서는 경고를 하는 게 허용된다.