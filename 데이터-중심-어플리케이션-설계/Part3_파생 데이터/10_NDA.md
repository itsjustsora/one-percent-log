> 한 사람의 영향도가 너무 큰 시스템은 성공하기 어렵다. 초기 설계가 완료되고 상당히 견고해지면 여러 사람이 다양한 관점을 가지고 각각 실험을 진행하면서 실제 테스트가 시작된다.
- 도널드 크누스
>

**[세 가지 유형의 시스템]**

|  | 서비스(온라인 시스템) | 일괄 처리 시스템
(오프라인 시스템) | 스트림 처리 시스템
(준실시간 시스템) |
| --- | --- | --- | --- |
| 설명 | 서비스는 클라이언트로부터 요청이나 지시가 올 때까지 기다린다. | 매우 큰 입력 데이터를 받아 데이터를 처리하는 작업을 수행하고 결과 데이터를 생산한다. | 요청에 대해 응답하지 않으며 입력 데이터를 소비하고 출력 데이터를 생산한다. |
| 주요 성능 지표 | 응답 시간, 가용성 | 처리량(입력 데이터 중 특정 크기만큼 처리할 때 걸리는 시간) |  |
- 일괄 처리는 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션을 구축하는 데 매우 중요한 구성요소다.
- 일괄 처리 알고리즘인 맵리듀스(MapReduce)로 왜 일괄 처리가 유용한지 명확하게 그림을 그려보고 이해해 보자.

**[유닉스 명령어]**

| 명령어 | 설명 | 예제                                                                                                                                        |
| --- | --- |-------------------------------------------------------------------------------------------------------------------------------------------|
| awk | 텍스트 파일에서 특정 필드나 패턴을 추출하거나 조작 | 두 번째 필드만 출력<br> `awk ‘{pring $2}’ file.txt`                                                                                               |
| sed | 파일이나 입력 스트림에서 문자열 치환, 삭제, 삽입 등의 작업 수행 | 모든 ‘apple’를 ‘orange’로 치환 <br>`sed ‘s/apple/orange/g’ file.txt`                                                                            |
| grep | 특정 문자열이나 정규표현식을 포함한 줄 검색 | 대소문자 구분 없이 검색<br>`grep -i ‘hello’ file.txt`                                                                                               |
| sort | 줄 단위로 데이터 정렬 (숫자, 역순, 특정 필드 기준) | 숫자 기준 정렬<br>`sort -n numbers.txt`                                                                                                         |
| uniq | 연속된 중복 줄 제거 (sort와 함께 사용해야 정확) | 중복 제거<br>`sort file.txt \| uniq`                                                                                                          |
| xargs | 파이프로 전달된 결과를 인수로 변환해 명령어 실행에 사용 | 파일 목록을 인수로 받아 삭제<br>`ls rm *.log \| xargs rm`                                                                                             
| head | 파일의 처음 몇 줄 출력 (기본: 10줄) | 앞의 5줄만 출력<br>                                                                                              `head -n 5 file.txt`           |
| less | 텍스트 파일을 한 페이지씩 보면서 스크롤, 검색 | 로그 파일 보기<br>                                                                                                       `less /var/log/syslog` |

<br>

[개념 사전]

| 단어 | 설명 |
| --- | --- |
| 발칸화(Balkanization) | 인터넷이 고립된 여러 개의 섬처럼 나뉘어 있는 현상이나 프로그램 언어나 데이터 파일 포맷 등이 분화발전하는 것 |

<br>

## 새롭게 알게 된 점(New)

### 유닉스 도구로 일괄 처리하기

**[1] 단순 로그 분석**

`sort` 유틸리티는 메모리보다 큰 데이터셋을 자동으로 디스크로 보내고, 자동으로 여러 CPU 코어에서 병렬로 정렬한다.

- 메모리 부족 없이 손쉽게 큰 데이터셋으로 확장 가능하다.

<br>

**[2] 유닉스 철학**

> *“다른 방법으로 데이터 처리가 필요할 때 정원 호스와 같이 여러 다른 프로그램을 연결하는 방법이 필요하다. 이것은 I/O 방식이기도 하다.”*
> - 더그 맥일로이(Doug McIlory), 유닉스 파이프 발명

1. 각 프로그램이 한 가지 일만 하도록 작성하라.
2. 모든 프로그램의 출력은 아직 알려지지 않은 다른 프로그램의 입력으로 쓰일 수 있다고 생각하라.
3. 소프트웨어를 빠르게 써볼 수 있게 설계하고 구축하라.
4. 프로그래밍 작업을 줄이려면 미숙한 도움보단 도구를 사용하라.

<br>

**1️⃣ 동일 인터페이스**

특정 프로그램이 다른 어떤 프로그램과도 연결 가능하려면 프로그램 모두가 같은 입출력 인터페이스를 사용해야 한다.

- 유닉스에서의 인터페이스는 단지 **순서대로 정렬된 바이트의 연속**인 `파일(파일 디스크립처)`이다.
- 파일은 단순해서 같은 인터페이스로 파일시스템의 실제 파일, 프로세스 간의 통신 채널, TCP 연결을 나타내는 소켓 등 다른 여러 가지 것을 표현할 수 있다.

<br>

> 🔉 ”**Everything is a file”**  
유닉스 시스템에서는 다양한 리소스를 모두 파일처럼 다루는 것처럼 설계되어 있다. 그러니까 어떠한 다른 시스템 자원이어도 동일한 함수를 사용할 수 있다는 것이다.


<br>

**2️⃣ 투명성과 실험**

> 유닉스 도구가 성공적인 이유 중 하나는 **진행 사항을 파악하기가 상당히 쉽기 때문**이다.
>
- 유닉스 명령에 들어가는 입력 파일은 일반적으로 불변으로 처리된다.
- 어느 시점이든 파이프라인을 중단하고 출력을 파이프를 통해 `less`로 보내 원하는 형태의 출력이 나오는지 확인할 수 있다.
- 특정 파이프라인 단계의 출력을 파일에 쓰고 그 파일을 다음 단계의 입력으로 사용할 수 있다.

⇒ 유닉스 도구를 사용하는 데 가장 큰 제약은 **단일 장비**에서만 실행된다느 점이다. 바로 이 점이 **하둡**같은 도구가 필요한 이유다.

<br>

### 맵리듀스와 분산 파일 시스템

> 맵리듀스는 유닉스 도구와 비슷한 면이 있지만 수천 대의 장비로 분산해서 실행이 가능하다는 점에서 차이가 있다.
>
- 맵리듀스 작업은 입력을 수정하지 않기 때문에 출력을 생산하는 것 외에 다른 부수 효과는 없다.
- 분산 파일 시스템 상의 파일을 입력과 출력으로 사용한다.
- 하둡 맵리듀스 구현에서 이 파일 시스템은 HDFS(Hadoop Distributed File System)라고 하는데 GFS(Google File System)를 재구현한 오픈소스다.
- HDFS는 비공유 원칙을 기반으로 하는데 NAS(Network Attached Storage)와 SAN(Storage Area Network) 아키텍처에서 사용하는 공유 디스크 방식과는 반대다.
- 공유 디스크 저장소는 중앙 집중 저장 장치를 사용하는 데 맞춤형 하드웨어를 사용하거나 파이버 채널(Fibre Channel)과 같은 특별한 네트워크 인프라를 사용하기도 한다.
- 반면 비공유 방식은 특별한 하드웨어가 필요없다. 일반적인 데이터센터 네트워크에 연결된 컴퓨터면 충분하다.
- HDFS는 개념적으로는 매우 큰 하나의 파일 시스템이고 데몬이 실행 중인 모든 장비의 디스크를 사용할 수 있다.
    - HDFS는 각 장비에서 실행되는 데몬 프로세스로 구성된다.
    - 데몬 프로세는 다른 노드가 해당 장비에 저장된 파일에 접근 가능하게끔 네트워크 서비스를 제공한다.
    - 네임노드(NameNode)라고 부르는 중앙 서버는 특정 파일 블록이 어떤 장비에 저장됐는지 추적한다.
- 장비가 죽거나 디스크가 실패하는 경우에 대비하기 위해 파일 블록은 여러 장비에 복제된다.
    - 단순히 여러 장비에 동일한 데이터를 복사하는 방식
    - 리드 솔로몬 코드(Read-Solomon code) 같은 삭제 코딩(erasure coding) 방식을 사용해 데이터 전체를 복제하는 것보다 적은 저장소 부담으로 손실된 데이터를 복구하는 방식
- HDFS는 확장성이 뛰어나다.

<br>

**[1] 맵리듀스 작업 실행하기**

> 맵리듀스는 HDFS 같은 분산 파일 시스템 위에서 대용량 데이터셋을 처리하는 코드를 작성하는 프로그래밍 프레임워크다.
>

**맵 리듀스의 데이터 처리 패턴**

1단계. 파일을 나누어 레코드를 만든다.

2단계. 각 입력 레코드마다 매퍼 함수를 호출해 키와 값을 추출한다. (맵)

3단계. 키를 기준으로 키-값 쌍을 모두 정렬한다.

4단계. 리듀스 함수를 호출한다. (리듀스)

**두 가지 콜백 함수** 

맵리듀스 프레임워크는 `매퍼`가 생산한 키-값 쌍을 받아 같은 키를 가진 레코드를 모으고 해당 값의 집합을 반복해 `리듀서` 함수를 호출한다.

| 매퍼(Mapper) | 리듀서(Reducer) |
| --- | --- |
| 입력 레코드로부터 키와 값을 추출 (정렬에 적합한 형태로 데이터를 준비하는 역할) | 출력 레코드 생산 (정렬된 데이터를 가공하는 역할) |

<br>

**1️⃣ 맵리듀스의 분산 실행**

> 맵리듀스 작업의 병렬 실행은 `파티셔닝`을 기반으로 한다. 작업 입력으로 `HDFS`상의 디렉터리를 사용하는 것이 일반적이고, 입력 디렉터리 내 각 파일 또는 파일 블록을 독립된 `맵 태스크`에서 처리할 독립 파티션으로 간주한다.
>


- 맵 태스크 수는 입력 파일의 블록 수로 결정되지만 리듀스 태스크 수는 사용자가 설정한다.
- 특정 키-값 쌍이 어느 리듀스 태스크에서 수행될지 결정하기 위해 키의 해시값을 사용한다.
- 정렬 : 각 맵 태스크는 키의 해시값을 기반으로 출력을 리듀서로 파티셔닝하고, 각 파티션을 매퍼의 로컬 디스크에 정렬된 파일로 기록한다.
- `셔플(suffle)` : 리듀서를 기준으로 파티셔닝하고 정렬한 뒤 매퍼로부터 데이터 파티션을 복사하는 과정

<br>

**2️⃣ 맵 리듀스 워크플로**

> 맵리듀스 작업 하나로 해결할 수 있는 문제의 범위는 제한적이라 각 작업을 연결해 워크플로(workflow)로 구성하는 방식은 꽤 일반적이다.
>
- 연결된 맵리듀스 작업은 각 명령의 출력을 임시 파일에 쓰고 다음 명령이 그 임시 파일로부터 입력을 읽는 방식에 더 가깝다.
- 워크플로 상에서 선행 작업이 완전히 끝나야만 다음 작업을 시작할 수 있어 하둡 맵리듀스 작업 간 수행 의존성을 관리하기 위해 다양한 스케줄러가 개발됐다.
- 피그(Pig), 하이브(Hive) 등과 같은 다양한 하둡용 고수준 도구는 다중 맵리듀스를 서로 적절하게 자동으로 엮어 워크플로를 설정한다.

<br>

**[2] 리듀스 사이드 조인과 그룹화**

일괄 처리 맥락에서 조인은 데이터셋 내 모든 연관 관계를 다룬다는 뜻이다. 여러 장비에 걸쳐 병렬 처리가 가능한 경우는 입력 전체를 스캔하는 것이 상당히 합리적이다.

<br>

**1️⃣ 사용자 활동 이벤트 분석 예제**

- 나쁜 예 : 하나씩 활동 이벤트를 훑으며 나오는 사용자 ID 마다 DB 질의 보내기
    - 질의 통신으로 인한 왕복 시간으로 처리량 제한, 많은 질의 병렬 실행으로 데이터베이스 과부하
- 좋은 예 : 사용자 데이터베이스의 사본을 가져와 사용자 활동 레코드가 저장된 분산 파일 시스템에 넣기

<br>

**2️⃣ 정렬 병합 조인**

- 키로 매퍼의 출력을 파티셔닝해 키-값 쌍으로 정렬한다면 같은 사용자의 활동 이벤트와 사용자 레코드는 리듀서의 입력으로 서로 인접해서 들어간다.
- `보조 정렬(secondary sort)` : 리듀서가 사용자 데이터베이스를 먼저 보고 활동 이벤트를 시간 순으로 보게하는 식으로 작업 레코드를 재배열 하는 것
- 정렬 병합 조인(sort-merge join) : 조인의 양측의 정렬된 레코드 목록을 병합

<br>

**3️⃣ 같은 곳으로 연관된 데이터 가져오기**

- 병합 정렬 조인 중 매퍼와 정렬 프로세스는 특정 사용자 ID로 조인 연산을 할 때 필요한 모든 데이터를 한 곳으로 모은다. 그래서 사용자 ID별로 리듀서를 한 번만 호출한다.
    - 처리량 UP, 메모리 부담 LOW
- 맵리듀스 프로그래밍 모델은 올바른 장비로 데이터를 모으는 연산의 물리적 네트워크 통신 측면과 받은 데이터를 처리하는 애플리케이션 로직을 분리한다.

<br>

**4️⃣ 쏠림 다루기** 

> 조인 입력에 핫 키(hot key)가 존재하는 경우에 핫스팟을 완화할 방법은 무엇인가?
>
- 피그(Pig)의 쏠린 조인(skewed join) 메서드
    - 어떤 키가 핫 키인지 결정하기 위해 샘플링 작업 수행
    - 실제 조인을 수행할 때 매퍼는 핫 키를 가진 레코드는 여러 리듀서 중 임의로 선택한 하나로 레코드를 보낸다. 핫 키로 조인할 다른 입력은 핫 키각 전송된 모든 리듀서에 복제한다.
    - 비용이 들지만 병렬화 효과가 훨씬 큼
- 크런치(Crunch)의 공유 조인(shared join) 메서드
    - 핫 키를 명시적으로 지정한다.
- 하이브(Hive)
    - 핫 키는 테이블 메타데이터에 명시적으로 지정하고 핫 키와 관련된 레코드를 나머지 키와는 별도 파일에 저장한다.
    - 해당 테이블에서 조인할 때 핫 키를 가지는 레코드는 맵 사이드 조인(map-side join)을 사용해 처리한다.
- 핫 키로 레코드를 그룹화하고 집계하는 작업
    - 첫 번째 맵리듀스 단계. 레코드를 임의의 리듀서로 보낸다. 각 리듀서는 핫 키 레코드의 일부를 그룹화하고 키별로 집계해 간소화한 값을 출력한다.
    - 두 번째 맵리듀스 작업. 첫 단계 모든 리듀서에서 나온 값을 키별로 모두 결합해 하나의 값으로 만든다.

<br>

**[3] 맵 사이드 조인**

| 방법 | 리듀스 사이드 조인(reduce-side join) | 맵사이드 조인(map-side join) |
| --- | --- | --- |
| 정의 | 실제 조인 로직을 리듀서에서 수행 | 입력 데이터에 대해 특정 가능일 가능할 때 사용할 수 있는 축소된 맵리듀스 작업 |
| 장점 | 입력 데이터에 대한 특정 가정이 필요없다. | 빠른 조인 수행이 가능하다. |
| 단점 | 정렬 후 리듀서로 복사한 뒤 리듀서 입력을 병합하는 모든 과정에 드는 비용이 크다. |  |

<br>

**1️⃣ 브로드캐스트 해시 조인(broadcast hash join)**

- 큰 입력의 파티션 하나를 담당하는 각 매퍼는 작은 입력 전체를 읽는다.
- 작은 조인 입력을 인메모리 해시 테이블로 적재하는 대신 로컬 디스크에 읽기 전용 색인으로 저장하기도 한다.

<br>

**2️⃣ 파티션 해시 조인**

- 제대로 파티셔닝이 작동했다면 각 매퍼는 각 입력 데이터셋 중 파티션 한 개만 읽어도 충분하다.
- 각 매퍼의 해시 테이블에 적재해야 할 데이터의 양을 줄일 수 있다.

<br>

**3️⃣ 맵 사이드 병합 조인**

입력 데이터셋이 같은 방식으로 파티셔닝됐을 뿐 아니라 같은 키를 기준으로 정렬됐다면 변형된 맵 사이드 조인을 적용할 수 있다.

<br>

**4️⃣ 맵리듀스 워크플로**

- 맵 사이드 조인을 수행하기 위해서는 크기, 정렬, 입력 데이터의 파티셔닝 같은 제약 사항이 따른다.
- 조인 전략을 최적화할 때는 파티션 수가 몇 개인지, 데이터가 어떤 키를 기준으로 파티셔닝되고 정렬됐는지도 꼭 알아야 한다.

<br>

**[4] 일괄 처리 워크플로의 출력**

> 모든 처리를 마친 결과가 어떻게 나오고, 애초에 이 모든 작업을 수행하는 이유가 무엇인가?
>

<br>

**1️⃣ 검색 색인 구축**

> 맵리듀스는 구글에서 검색 엔진에 사용할 색인을 구축하기 위해 처음 사용됐다.
>
- 정해진 문서 집합을 대상으로 전문 검색이 필요하다면 일괄 처리가 색인을 구축하는 데 매우 효율적이다.
- 매퍼는 필요에 따라 문서 집합을 파티셔닝하고 각 리듀서가 해당 파티션에 대한 색인을 구축한다.
- 문서 기준으로 파티셔닝해 색인을 구축하는 과정은 병렬화가 매우 잘 된다.

<br>

**2️⃣ 키-값 저장**

> 일괄 처리 워크플로 출력의 예로 머신러닝 시스템(스팸 필터, 이미지 인식 등), 추천 시스템 등을 구축할 수 있다.
>
- 일괄 처리 작업의 출력은 일종의 데이터베이스가 된다.
- **배치 프로세스의 출력을 데이터베이스로 보내는 방법**
  - `방법1` 매퍼와 리듀서 내에서 선호하는 데이터베이스 클라이언트 라이브러리를 사용해 일괄 처리 작업이 한번에 레코드 하나씩 데이터베이스 서버로 직접 요청 보내기
  - `방법2` 일괄 처리 작업 내부에 완전히 새로운 데이터베이스를 구축해 분산 파일 시스템의 작업 출력 디렉터리에 자정하기

<br>

**3️⃣ 철학**

> 유닉스 철학은 데이터플로가 ‘프로그램이 입력을 읽어 출력을 내놓는다’로 명확하기 때문에 실험을 장려한다. 맵리듀스 작업도 마찬가지 철학으로 출력을 취급한다.
>
- 입력을 불변으로 처리하고 외부 데이터베이스에 기록하는 등의 부수 효과를 피하기 때문에 일괄 처리 작업은 좋은 성능을 내면서도 유지보수가 훨씬 간단하다.

<br>

**[5] 하둡과 분산 데이터베이스의 비교**

- `대규모 병렬 처리(MPP, massively parallel processing) 데이터베이스`는 장비 클러스터에서 분석 SQL 질의를 병렬로 수행하는 것에 초점을 둔다.
- `맵리듀스`와 `분산 파일 시스템`의 조합은 **아무 프로그램**이나 실행할 수 있는 **운영체제**와 비슷한 속성을 제공한다.

| 구분 | 하둡(Hadoop)                                                                                                         | MPP 데이터베이스                                                                                               |
| --- |--------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|
| 저장소의 다양성 | ① 데이터 형태에 상관없이 HDFS에 저장 가능<br>② 스키마는 나중에 적용<br>③ 다양한 데이터를 빠르게 수집                                                   | ① 데이터와 질의 형태 선행 모델링 필요<br>② 세심한 스키마 설계로 중앙 집중식 수집 속도 저하                                                  |
| 처리 모델의 다양성 | ① SQL 질의 실행 엔진 구축 가능<br>② 다양한 일괄 처리 형태 작성 가능<br>③ 동일 클러스터 내 다양한 작업 부하 유연하게 처리 가능                                   | ① 설계된 질의 유형에 대해 좋은 성능 확보<br>② SQL 질의로 모든 종류의 처리 표현 불가                                                    |
| 결함 대응 설계 | ① 개별 태스크 단위 재실행 가능으로 전체 작업에 영향주지 않음<br>② 디스크 기반 처리 (내결함성 확보, 큰 데이터셋) | ① 한 장비의 장애 시 전체 질의 중단                                                            <br>② 메모리 중심 처리 (비용 문제) |
- `데이터 호수(data lake)`, `엔터프라이즈 데이터 허브(enterprise data hub)` : 원시 데이터를 수집하고 스키마 설계를 추후에 수행하여 다양한 데이터를 **빠르게 수집**할 수 있는 **구조적 특성을 가진다**.
- `초밥 원리(sushi principle)` : “원시(raw) 데이터”가 더 좋다는 접근법

<br>

### 맵리듀스를 넘어

**[1] 중간 상태 구체화**

- `중간 상태(Intermediate state)` : 분산 파일 시스템 상에 있는 파일들이 단순히 한 작업에서 다른 작업으로 데이터를 옮기는 수단이 된 것
- `구체화(materialization)` : 중간 상태를 파일로 기록하는 과정
- 단점
  - 입력을 생성하는 모든 선행 작업이 완료됐을 때만 시작 가능하다.
  - 매퍼가 종종 중복된다.
  - 임시 데이터의 경우, 중간 상태 파일들로 여러 장비에 걸쳐 복제된다는 것은 과잉조치이다.

<br>

**1️⃣ 데이터플로 엔진**

> 전체 워크플로를 독립된 하위 작업으로 나누지 않고 작업 하나로서 다루는 엔진들은 여러 처리 단계를 통해 데이터 흐름을 명시적으로 모델링하기 때문에 `데이터플로 엔진(dataflow engine)`이라고 부른다.
>
- 맵리듀스처럼 단일 스레드에서 사용자 정의 함수를 반복 호출해 한번에 레코드 한 개씩 처리한다.
- 입력을 파티셔닝해 병렬화한다.
- 한 함수의 출력을 다른 함수의 입력으로 사용하기 위해 네트워크를 통해 복사한다.
- 일반적으로 맵리듀스 워크플로에 비해 수행 속도가 훨씬 빠르다. (최적화)

<br>

**2️⃣ 내결함성**

- 맵리듀스는 중간 상태를 모두 구체화하기 때문에 쉽게 내결함성을 확보한다. 태스크가 실패하더라도 다른 장비에서 태스크를 재실행할 수 있고 파일 시스템으로부터 동일한 입력을 다시 읽을 수 있다.
- 스파크와 플링크, 테즈는 HDFS에 중간 상태를 쓰지 않기 때문에 내결함성 확보를 위해 다른 접근법을 사용한다. 장비가 죽어서 장비에 있던 중간 상태까지 잃게 되면 아직 유효한 데이터로부터 계산을 다시 해서 복구한다.
- 연산자들이 항상 같은 출력을 생성하지 않는다면 결함이 전파될 수 있기에 연산자를 결정적으로 만드는 것이 좋다.

<br>

**[2] 그래프와 반복 처리**

**1️⃣ 프리글 처리 모델**

> 일괄 처리 그래프를 최적화하는 방법으로 `벌크 동기식 병렬(BSP, bulk synchronous parallel)` 연산 모델이 널리 사용된다.
>
- 반복할 때마다 개별 정점에서 함수를 호출해 그 정점으로 보내진 모든 메시지를 전달한다.
- 메시지 통신은 고정된 횟수 안에 처리하며, 각 반복에서 이전 반복에서 보내진 모든 메시지를 전달한다.
- 정점 사이의 메시지는 **내결함성**과 **지속성**이 있다.

<br>

**2️⃣ 내결함성**

- 메시지는 일괄 처리가 가능해 통신 중 대기 시간이 발생하지 않는다.
- `내결함성` : 반복이 끝나는 시점에 모든 정점의 상태를 주기적으로 체크포인트에 저장한다.

<br>

**3️⃣ 병렬 실행**

- 그래프 알고리즘은 네트워크 상에서 메시지를 보내는 오버헤드 때문에 심각하게 느려질 수 있다.
- 그래프가 단일 컴퓨터 메모리에 넣을 수 있는 크기라면, 단일 장비 알고리즘이 분산 일괄 처리보다 훨씬 성능이 좋을 가능성이 높다.
- 그래프가 단일 장비에 넣기에 너무 크다면 프리글 같은 분산 접근법을 꼭 사용해야 한다.

<br>

**[3] 고수준 API와 언어**

> 직접 맵리듀스 작업을 작성하는 일은 상당히 어렵기 때문에 하이브, 피그, 캐스캐이딩과 같은 고수준 언어나 API가 인기를 끌었다.
>

코드를 적게 작성해도 되는 명백한 이점뿐만 아니라 대화식 사용도 지원한다. 즉, 사용자가 시스템을 생산성 높게 사용할 수 있을 뿐 아니라 장비 수준에서도 작업을 더욱 효율적으로 수행할 수 있다.

<br>

**1️⃣ 선언형 질의 언어로 전환**

고수준 API에 선언적 측면을 포함하면서 실행 중에 이용할 수 있는 질의 최적화기를 가진다면 일괄 처리 프레임워크는 MPP 데이터베이스와 한층 비슷해진다.

<br>

## 어려웠거나 이해하지 못한 부분(Difficulty)

## 추가 내용(Amendment)