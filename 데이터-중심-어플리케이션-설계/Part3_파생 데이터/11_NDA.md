> *복잡하지만 잘 작동하는 시스템은 예외 없이 간단하지만 잘 작동하는 시스템으로부터 발전한다.
이 명제는 역도 참이다.
처음부터 복잡하게 설계된 시스템은 절대 작동할 리도 없고 작동하게 만들지도 못한다.*
**존 갈, 체계론(1975)**
>

<br>

**[스트림 처리의 기본 개념]**

고정된 시간 조각이라는 개념을 버리고 단순히 이벤트가 발생할 때마다 처리한다.

<br>

**[개념 사전]**

| 단어 | 의미 |
| --- | --- |
| 이벤트 스트림 | 일괄 처리 데이터와는 반대로 한정되지 않고 점진적으로 처리되는 데이터 관리 메커니즘 |


<br>

## 새롭게 알게 된 점 (New)

### 이벤트 스트림 전송

> 🤔 일괄 처리 환경에서 작업은 입출력이 파일이다. 그러면 스트림 처리에서는 어떨까?
>
- 이벤트는 텍스트 문자열이나 JSON 또는 이진 형태 등으로 부화되며 이 과정을 통해 저장할 수 있다.
- `생산자(producer, 발행자(publisher), 발송자(sender))`가 이벤트를 만들면 **복수**의 `소비자(consumer, 구독자(subscriber) 또는 수신자(recipient))`가 처리할 수 있다.
- 파일 시스템에서는 관련 레코드 집합을 파일 이름으로 식별하지만 스트림 시스템에서는 대개 `토픽(topic)`이나 `스트림`으로 관련 이벤트를 묶는다.

<br>

**[1] 메시징 시스템(messaging system)**

> 🤔 생산자가 소비자가 메시지를 처리하는 속도보다 빠르게 전송하다면 어떻게 될까?
>

**시스템이 할 수 있는 선택지**

- 메시지를 버린다.
- 큐에 메시지를 버퍼링한다.
- `배압`을 적용해서 생산자가 메시지를 더 보내지 못하게 막는다.

<Br>

> 🔉 메시지가 큐에 버퍼링될 때 큐 크기가 메모리 크기보다 커지면 시스템이 중단되는지, 메시지를 디스크에 쓰는지, 디스크에 쓴다면 디스크 접근이 시스템의 성능에 어떤 영향을 주는지까지 이해하는 것이 중요하다.


<Br>

**1️⃣ 직접 메시징 시스템**

- 많은 메시지 시스템은 중간 노드를 통하지 않고 생산자와 소비자를 네트워크로 직접 통신한다.
- 직접 메시징 시스템은 설계 상황에서는 잘 동작하지만 메시지가 유실될 가능성을 고려해서 애플리케이션 코드를 작성해야 한다.
- 일부 프로토콜은 실패한 메시지 전송을 생산자가 재시도하게끔 하지만 생산자 장비가 죽어버리면 재시도하려고 했던 메시지 버퍼를 잃어버릴 수 있기 때문에 문제가 있다.

<br>

> 🔉 **UDP 멀티캐스트**는 낮은 지연이 필수인 주식 시장과 같은 금융 산업에서 널리 사용된다. UDP 자체는 신뢰성이 낮아도 애플리케이션 단의 프로토콜은 읽어버린 패킷을 복구할 수 있다.

<br>

**2️⃣ 메시지 브로커**

> **직접 메시징 시스템의 대안**으로 널리 사용된다. 근본적으로 메시지 스트림을 처리하는 데 최적화된 데이터베이스의 일종이다.
>
- 브로커가 장애로 중단됐을 때 메시지를 잃어버리지 않기 위해 디스크에 메시지를 기록할 수 있다. (혹은 메모리에만)
- 소비 속도가 느린 소비자가 있으면 일반적으로 큐가 제한 없이 계속 늘어나게 한다.
- **비동기 동작** : 생산자가 메시지를 보낼 때 생산자는 브로커가 해당 메시지를 버퍼에 넣었는지만 확인, 소비자가 메시지를 처리하기까지 기다리지 않는다.

<br>

**3️⃣ 메시지 브로커 vs. 데이터베이스**

| 구분 | 메시지 브로커 | 데이터베이스 |
| --- | --- | --- |
| 데이터 삭제 시점 | 소비자에게 데이터 배달이 성공할 경우 | 데이터가 삭제될 경우 |
| 데이터 검색 | 특정 패턴과 부합하는 토픽의 부분 집합 구독 방식 지원 | 보조 색인 및 다양한 방법 지원 |
| 질의  결과 | 데이터가 변하면 클라이언트에게 알림 |                                                  질의 시점의 데이터 스냅숏 기준 |

<br>

**4️⃣ 복수 소비자**

복수 소비자가 같은 토픽에서 메시지를 읽을 때 사용하는 주요 패턴 두 가지

<br>

**5️⃣ 확인 응답과 재전송**

- 메시지를 유실하지 않기 위해 메시지 브로커는 확인 응답을 사용한다.
- 메시지 브로커는 JMS와 AMQP 표준에서 요구하는 대로 메시지 순서를 유지하려 노력할지라도 부하 균형 분산과 메시지 재전송을 조합하면 필연적으로 메시지 순서가 변경된다.

<br>

**[2] 파티셔닝된 로그**

> **데이터베이스의 지속성 있는 저장 방법**과 **메시징 시스템의 지연 시간이 짧은 알림 기능**을 조합할 수 없을까? 이것이 `로그 기반 메시지 브로커(log-based message broker)`의 기본 아이디어어다.
>

<br>

**1️⃣ 로그를 사용한 메시지 저장소**

> 생산자가 보낸 메시지는 로그 끝에 추가하고 소비자는 로그를 순차적으로 읽어 메시지를 받는다. 소비자가 로그 끝에 도달하면 새 메시지가 추가됐다는 알림을 기다린다.
>
- 디스크 하나를 쓸 때보다 처리량을 높이기 위해 확장하는 방법으로 로그를 파티셔닝하기도 한다.
- 각 파티션은 다른 파티션과 독립적으로 읽고 쓰기가 가능한 분리된 로그가 된다.
- `토픽`은 같은 형식의 메시지를 전달하는 파티션들의 그룹으로 정의한다.

<br>

**로그 기반 메시지 브로커**

*아파치 카프카(Apache Kafka), 아마존 키네시스 스트림(Amazon Kinesis Stream), 트위터의 분산 로그(DistributiedLog)*

- 각 파티션 내에서 브로커는 모든 메시지에 `오프셋(단조 증가하는 순번)`을 부여한다.
- 모든 메시지를 디스크에 저장하지만 여러 장비에 메시지를 파티셔닝해 초당 수백만 개의 메시지를 처리할 수 있고, 메시지를 복제함으로써 장애에 대비할 수 있다.

<br>

**2️⃣ 로그 방식 vs. 전통적인 메시징 방식**

|  | 장점                                                                  | 단점 |
| --- |---------------------------------------------------------------------| --- |
| 로그 기반 시스템 | ❶ 여러 소비자가 독립적으로 로그 읽기 가능 (팬 아웃 처리)<br>❷ 메시지 읽기 순서 보장<br>❸ 메시지 유지 가능 | ❶ 개별 메시지가 아닌 파티션 단위로 할당 *(메시지 단위 병렬 처리 어려움)*<br>❷ 작업을 공유하는 노드 수 ≤ 해당 토픽의 로그 파티션 수 제한<br>❸ 특정 메시지 지연 시 후속 메시지 처리까지 지연 |

🤔 메시지를 처리하는 비용이 비싸고 메시지 단위로 병렬화 처리하고 싶지만 메시지 순서는 중요하지 않다면?

→ `JMS/AMQP 방식`

🤔 처리량이 많고 메시지를 처리하는 속도가 빠르지만 메시지 순서가 중요하다면?

→ `로그 기반 접근법`

<br>

**3️⃣ 소비자 오프셋**

> 파티션 하나를 순서대로 처리했을 때의 장점
>
- 브로커는 주기적으로 소비자 오프셋을 기록하면 될뿐, 모든 개별 메시지마다 보내는 확인 응답을 추적하지 않아도 된다.
- 추적 오버헤드 감소 | 일괄 처리, 파이프라이닝 수행 기회 제공 → **로그 기반 시스템의 처리량 확장**
- 소비자 노드에 장애가 발생하면 마지막 기록된 오프셋부터 메시지를 처리한다.

<br>

**4️⃣ 디스크 공간 사용**

- `원형 버퍼(circular buffer)` or `링 버퍼(ring buffer)` : 로그는 크기가 제한된 버퍼로 구현하고 버퍼가 가득 차면 오래된 메시지 순서대로 버린다.
- 메시지 보관 기간과 관계없이 모든 메시지를 디스크에 기록하기 때문에 로그 처리량은 일정하다.

<br>

**5️⃣ 소비자가 생산자를 따라갈 수 없을 때**

- 소비자의 로그의 헤드로부터 얼마나 떨어졌는지 모니터링하면 눈에 띄게 뒤처지는 경우 경고할 수 있다.
- 어떤 소비자가 너무 뒤처져서 메시지를 잃기 시작해도 해당 소비자만 영향을 받고 다른 소비자들의 서비스를 망치지 않기 때문에 운영상 상당히 유리하다.
- 소비자가 종료되거나 죽으면 자원소비가 중단되고 소비자 오프셋만 남는다.
    - 전통적인 브로커의 경우 해당 소비자가 사용하던 큐를 삭제해줘야 한다.

<br>

**6️⃣ 오래된 메시지 재생**

- 메시지를 소비하는 것은 로그를 변화시키지 않는 읽기 전용 연산이다.
- 유일한 부수 효과는 `소비자 오프셋 이동`으로, 처리 코드를 변경해 특정 분량의 메시지를 재처리할 수 있다.
- 로그 기반 메시징 시스템은 이처럼 많은 실험을 할 수 있고 오류가 버그를 복구하기 쉽다.

<br>

### 데이터베이스와 스트림

**[1] 시스템 동기화 유지하기**

> 여러 시스템에서 데이터의 복제본을 가지고 있고 목적에 맞게 최적화된 형태로 저장될 때, 동기화하기 위해 덤프 작업이 필요하다. 이때 데이터베이스 전체를 덤프하는 작업이 너무 느리면 어떻게 할까?
>
- `이중기록(dual write)` : 데이터가 변할 때마다 애플리케이션 코드에서 명시적으로 각 시스템에 기록한다.
- **다중 리더 시스템**에서는 동시에 쓰여진 값을 알아채지 못하거나, 모든 쓰기가 성공하지 않아 각 시스템 간 불일치가 발생할 수 있다.

<br>

**[2] 변경 데이터 캡처(CDC, change data capture)**

> 파생 데이터 시스템이 레코드 시스템의 정확한 데이터 복제본을 가지게 하기 위해 레코드 시스템에 발생하는 모든 변경 사항을 파생 데이터 시스템에 반영하는 것을 보장하는 메커니즘
>


- 데이터가 기록되자마자 변경 내용을 스트림으로 제공할 수 있으면 특히 유용하다.

<br>

**1️⃣ 구현**

- 변경 사항을 캡처할 데이터베이스 하나를 리더로 하고 나머지를 팔로워로 한다.
- 로그 기반 메시지 브로커는 메시지 순서를 유지하기 때문에 원본 데이터베이스에서 변경 이벤트를 전송하기에 적합하다.
- **데이터베이스 트리거를 사용**하기도 하지만 고장 나기 쉽고 성능 오버헤드가 상당하다.
- **복제 로그를 파싱하는 방식**은 스키마 변경 대응 등 해결해야 할 여러 문제가 있지만 트리거 방식보다 견고하다.
- **비동기 방식**으로 동작하며 느린 소비자가 추가되더라도 레코드 시스템에 미치는 여향이 적으나, 복제 지연의 모든 문제가 발생한다.

<br>

**2️⃣ 초기 스냅숏**

- 전체 로그 히스토리가 없다면 일관성 있는 스냅숏을 사용해야 한다.
- 변경 로그의 위치나 오프셋에 대응되어야 스냅숏 이후에 변경 사항을 적용할 시점을 알 수 있다.

<br>

**3️⃣ 로그 컴팩션(log compaction)**

> 🤔 로그 히스토리의 양이 제한되면, 새로운 파생 데이터 시스템을 추가할 때마다 스냅숏을 만들어야 할까?
>
- 모든 변경에 기본키가 포함되게 하고, 키의 모든 갱신이 해당 키의 이전 값을 교체하게 해서 특정 키에 대한 최신 쓰기를 유지하자.
- `아파치 카프카`는 로그 컴팩션 기능을 제공한다.

<br>

**4️⃣ 변경 스트림용 API 지원**

최근 데이터베이스들은 기능 개선이나 리버스 엔지니어링을 통해 CDC 지원을 하기보다 점진적으로 변경 스트림을 기본 인터페이스로 지원하기 시작했다.

| 데이터베이스                             | 설명 |
|------------------------------------| --- |
| 리싱크DB(RethinkDB)                   | 질의 결과에 변경이 있을 때 알림을 받을 수 있게 구독이 가능한 질의를 지원한다. |
| 파이어베이스(FireBase)<br>카우치DB(CouchDB) | 애플리케이션도 사용 가능한 변경 피드 기반의 데이터 동기화를 지원한다. |
| 미티어(Meteor)                        | 몽고DB의 oplog를 사용해 데이터 변경사항을 구독하거나 사용자 인터페이스를 갱신한다. |
| 볼트DB(VoltDB)                       | 스트림 형태로 데이터베이스에서 데이터를 지속적으로 내보내는 트랜잭션을 제공한다. |
| 카프카 커넥트(Kafka Connect)             | 카프카를 광범위한 CDC로 활용할 수 있게 만들어졌으며, 파생 데이터 시스템을 갱신하는 데 사용 가능하다. |

<br>

**[3] 이벤트 소싱(event sourcing)**

- 변경 데이터 캡처와 유사하게 애플리케이션 상태 변화를 모두 변경 이벤트 로그로 저장한다.
- 이벤트 저장은 추가만 가능하고, 갱신이나 삭제는 권장하지 않거나 금지된다.
- 어떤 상황이 발생한 후에 상황 파악이 쉬워져, 디버깅에 도움이 되고 애플리케이션 버그를 방지한다.

<br>

**1️⃣ 이벤트 로그에서 현재 상태 파생하기**

- **이벤트 소싱을 사용하는 애플리케이션**은 시스템에 기록한 데이터를 표현한 이벤트 로그를 가져와 사용자에게 보여주기에 적당한 애플리케이션 상태로 변환해야 한다.
- `이벤트`는 **사용자 행동 의도를 표현**하므로 마지막 상태를 재구축하기 위해서는 전체 히스토리가 필요하다.(로그 컴팩션 불가능)
- `이벤트 소싱 시스템`에는 모든 원시 이벤트를 영원히 저장하고 필요할 때마다 모든 이벤트를 재처리할 수 있어야 한다는 의도가 있다.

<br>

**2️⃣ 명령과 이벤트**

> 이벤트 소싱 철학은 **이벤트**와 **명령(command)**을 구분하는 데 주의한다.
>
- 사용자 요청이 도착했을 때 이 요청은 `명령`이다.
- 이벤트는 생성 시점에 `사실(fact)`이며 나중에 추가된 이벤트는 독립적인 이벤트가 된다.
- 명령의 유효성은 이벤트가 되기 전에 동기식으로 검증해야 한다.
- 좌석 예약 시스템에서는 가예약 이벤트와 유효한 예약에 대한 확정 이벤트로 둘을 분리하여, 비동기 처리로 유효성 검사를 할 수 있다.

<br>

**[4] 상태와 스트림 그리고 불변성**

> *트랜잭션 로그는 데이터베이스에 적용된 모든 변경 사항을 기록한다. 로그는 고속으로 덧붙여지고, 덧붙이기가 로그를 변경하는 유일한 방법이다. 이런 측면에서 데이터베이스의 내용은 로그의 최근 레코드 값을 캐시하고 있는 셈이다. 즉 로그가 진실이다. 데이터베이스는 로그의 부분 집합의 캐시다. 캐시한 부분 집합은 로그로부터 가져온 각 레코드와 색인의 최신 값이다.*
펫 헬랜드(Pat Helland)
>

<br>

**1️⃣ 불변 이벤트의 장점**

- 잘못된 내역을 지우거나 덮어썼다면 문제 상황의 진단과 복구가 어렵다.(e.g. 회계 감사에서의 잘못된 거래내역 파악)
- 이벤트 로그에 기록된 정보로 현재 상태보다 훨씬 많은 정보를 포함할 수 있다. (e.g. 장바구니에 담았다가 취소한 항목 분석)

<br>

**2️⃣ 동일한 이벤트 로그로 여러 가지 뷰 만들기**

- 불변 이벤트 로그에서 가변 상태를 분리하면 동일한 이벤트 로그로 다른 여러 읽기 전용 뷰를 만들 수 있다.
- `명령과 질의 책임의 분리(command query responsibility segregation, CQRS)` : 데이터를 쓰는 형식과 읽는 형식을 분리해 다양한 읽기 뷰를 허용한다. (유연성 확보)

<br>

**3️⃣ 동시성 제어**

- 이벤트 로그의 소비가 대개 비동기이기 때문에, 기록한 이벤트가 아직 읽기 뷰에 반영되지 않았을 가능성이 있다.
- `해결책 1` 읽기 뷰의 갱신과 로그에 이벤트를 추가하는 작업을 동기식으로 수행한다. 같은 저장 시스템일 때 가능하다.
- `해결책 2` 이벤트 로그로 현재 상태를 만든다. 단일 이벤트를 한 번에 하나씩 처리하고, 파티션 내에서 이벤트의 직렬 순서를 정의하면 로그에서 동시성의 비결정성을 제거할 수 있다.

<br>

**4️⃣ 불변성의 한계**

> 🤔 영구적으로 모든 변화의 불변 히스토리를 유지하는 것이 어느 정도까지 가능할까?
>
- 데이터의 갱신과 삭제가 빈번히 일어나는 작업부하는 문제가 발생할 수 있따.
- 데이터 보호법에 따라 수행되어야 하는 데이터 삭제는 “찾기 불가능하게끔”하는 문제라기 보다는 “찾기 어렵게”하는 문제다.

<br>

### 스트림 처리

> 이번 장에서는 스트림을 처리해 다른 파생 스트림을 생산하는 것에 대해 설명한다. 이처럼 스트림을 처리하는 코드 조각을 `연산자(operator)`나 `작업(job)`이라고 부른다.
>
- 일괄 처리 작업과 가장 크게 다른 점은 **스트림은 끝나지 않는다**는 점이다.

<br>

**[1] 스트림 처리의 사용**

스트림 처리는 특정 상황이 발생하면 조직에 경고를 해주는 모니터링 목적으로 오랜 기간 사용돼 왔다.

<br>

**1️⃣ 복잡한 이벤트 처리(CEP, complex event processing)**

- CEP는 스트림에서 특정 이벤트 패턴을 찾는 규칙을 정의할 수 있어 이렇게 검색해야 하는 애플리케이션에 특히 적합하다.
- 질의는 오랜 기간 저장되고, 입력 스트림으로부터 들어오는 이벤트는 지속적으로 질의를 지나 흘러가면서 이벤트 패턴에 매칭되는 질의를 찾는다.

<br>

**2️⃣ 스트림 분석**

- 연속한 특정 이벤트 패턴을 찾는 것보다 대량의 이벤트를 집계하고 통계적 지표를 뽑는 것을 더 우선한다.
- 일반적으로 고정된 시간 간격 기준으로 통계를 개산한다.
- 일종의 최적화 기법으로 확률적 알고리즘을 사용한다.

<br>

**3️⃣ 구체화 뷰 유지하기**

- 어떤 데이터셋에 대한 또 다른 뷰를 만들어 효율적으로 질의할 수 있게 하고 기반이 되는 데이터가 변경될 때마다 뷰를 갱신한다.
- 구체화 뷰를 만들려면 잠재적으로 임의의 시간 범위에 발생한 모든 이벤트가 필요하다.

<br>

**4️⃣ 스트림 상에서 검색하기**

- 복수 이벤트로 구성된 패턴을 찾는 CEP 외에도 전문 검색 질의와 같은 복잡한 기준을 기반으로 개별 이벤트를 검색해야 하는 경우가 있다.

<br>

**5️⃣ 메시지 전달과 RPC**

- **아파치 스톰**의 `분산 RPC(distributed RPC)`를 사용하면, 이벤트 스트림을 처리하는 노드 집합의 질의를 맡길 수 있다.
- 액터 프레임워크를 이용해도 스트림 처리가 가능하나, 내결함성을 보장하지 못한다.

<br>

**[2] 시간에 관한 추론**

- 많은 스트림 처리 프레임워크는 윈도우 시간을 결정할 때 처리하는 장비의 시스템 시계(처리시간)를 이용한다.
- 이벤트가 실제로 발생한 시간보다 처리 시간이 많이 늦어지면 문제가 생긴다.

<br>

**1️⃣ 어떤 시계를 사용할 것인가**

> 이벤트 시간 기준으로 윈도우를 정의할 때 발생하는 까다로운 문제는 특정 윈도우에서 모든 이벤트가 도착했다거나 아직도 이벤트가 들어오고 있는지를 확신할 수 없다는 점이다.
>
- 이벤트의 타임스탬프는 실제 사용자와 상호작용이 발생했던 실제 시각이어야 한다.
- 잘못된 장치 시계를 조정하기 위해 세 가지 타임스탬프를 로그에 남기자.
  - 이벤트가 발생한 시간, 장치 시계를 따른다.
  - 이벤트를 서버로 보낸 시간, 장치 시계를 따른다.
  - 서버에서 이벤트를 받은 시간, 서버 시계를 따른다.

<br>

**2️⃣ 윈도우 유형**

| 구분 | 설명 |
| --- | --- |
| 텀블링 윈도우(Tumbling window) | 고정 길이를 사용하며, 모든 이벤트는 한 윈도우에 속한다. |
| 홉핑 윈도우(Hopping window) | 고정 길이를 사용하며, 결과를 매끄럽게 만들기 위해 윈도우를 중첩할 수 있다. |
| 슬라이딩 윈도우(Sliding window) | 각 시간 간격 시이에 발생한 모든 이벤트를 포함한다. |
| 세션 윈도우(Session window) | 고정된 기간이 없이 같은 사용자가 짧은 시간 동안 발생시킨 모든 이벤트를 그룹화해서 정의한다. |

<br>

**[3] 스트림 조인**

> 스트림 처리는 데이터 파이프라인을 끝이 없는 데이터셋의 증분 처리로 일반화하기 때문에 조인이 필요하다.
그러나 스트림 상에서 새로운 이벤트가 언제든 나타날 수 있기에 일괄 처리 작업에서 수행하는 조인보다 훨씬 수행이 어렵다.
>

<br>

**1️⃣ 조인의 종류**

세 가지 조인 유형 모두 스트림 처리자가 하나의 조인 입력을 기반으로 한 특정 상태를 유지해야 하고 다른 조인 입력에서 온 메시지에 그 상태를 질의한다.

| 구분 | 스트림 스트림 조인(윈도우 조인)                                                | 스트림 테이블 조인(스트림 강화) | 테이블 테이블 조인(구체화 뷰 유지) |
| --- |-------------------------------------------------------------------| --- | --- |
| 적용 예 | 사용자의 검색 활동 이벤트와 클릭 활동 이벤트를 함께 모아야 할 때                             | 사용자 활동 이벤트 집합과 사용자 프로필 데이터베이스를 함께 모아야 할 때 | 트위터 타임라인 문제 |
| 특징 | 스트림 처리자가 상태(state)를 유지해야 한다.<br>- 검색한 결과를 클릭했음/하지않았음을 말해주는 이벤트 방출 | 사용자의 활동 이벤트에 프로필 정보를 추가해 활동 이벤트를 강화(enriching)한다. | 질의 결과의 캐시가 타임라인이 되며 조인 대상 테이블이 변할 때마다 갱신된다. |

<br>
**2️⃣ 조인의 시간 의존성**

> 🤔 비슷한 시각에 다른 스트림에서 발생한 이벤트가 있으면 어떤 순서로 처리될까? 시간에 따라 변하는 상태를 조인해야 한다면 어느 시점을 조인에 사용해야 할까?
>
- `천천히 변하는 차원(SCD, slowly changing dimension)` : 시시각각 변하는 세율을 이용하는 질의 같이 동일한 입력으로 같은 작업을 재수행하더라도 반드시 같은 결과를 얻지 못하는 문제
- 조인되는 레코드의 특정 버전을 가리키는 데 유일한 식별자를 사용해 해결할 수 있다.
- 테이블에 있는 레코드의 모든 버전을 보유해야 하기 때문에 로그 컴팩션이 불가능하다.

<br>

**[4] 내결함성**

> 스트림 처리에서는 일괄 처리와 달리 출력을 노출하기 전에 태스크가 완료될 때까지 기다리는 것을 해결책으로 사용할 수 없다.
*스트림은 무한하고 그래서 처리를 절대 완료할 수 없기 때문이다.*
>

<br>

**1️⃣ 마이크로 일괄 처리와 체크포인트**

- `마이크로 일괄 처리(microbatching)` : 스트림을 작은 블록으로 나누고 각 블록을 소형 일괄 처리와 같이 다루는 방법
- 마이크로 일괄 처리는 `텀블링 윈도우`를 암묵적으로 지원한다.
- **아파치 플링크**는 주기적으로 상태의 롤링 체크포인트를 생성하고, 지속성 있는 저장소에 저장하여 장애가 발생했을 때 가장 최근 체크포인트에서 재시작될 수 있게 한다.
- 스트림 처리 프레임워크는 실패한 일괄 처리 출력을 지울 수 없어 실패한 태스크를 재시작할 수 있다.

<br>

**2️⃣ 원자적 커밋 재검토**

- 장애가 발생했을 때 정확히 한 번 처리되는 것처럼 보이려면 처리가 성공했을 때만 모든 출력과 이벤트 처리의 부수 효과가 발생하게 해야 한다.
- XA와는 다르게 이종 기술 간 트랜잭션을 지원하지 않는 대신 스트림 처리 프레임워크 내에서 상태 변화와 메시지를 관리해 트랜잭션을 내부적으로 유지한다.

<br>

**3️⃣ 멱등성**

외부 데이터에서 값을 기록할 때 메시지의 오프셋을 함께 포함해서 저장하면 반복해서 같은 갱신이 수행되는 것을 막을 수 있다.

<br>

**4️⃣ 실패 후에 상태 재구축하기**

- 원격 데이터 저장소에 상태를 유지하고 복제하는 방법이 있다.
- 스트림 처리자의 로컬에 상태를 유지하고 주기적으로 복제하는 방법이 있다.
- 작은 크기의 윈도우를 집계해서 만든 상태라면, 해당 윈도우에 해당하는 이벤트를 재생해도 충분히 빠르다.